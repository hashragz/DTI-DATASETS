{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Xm9NQpDa9ya"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from numpy import mean\n",
        "import csv\n",
        "from google.colab import drive\n",
        "from random import sample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import fbeta_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA8ilvZ5bDEi",
        "outputId": "af2874fb-67fb-4533-c3cb-bc067334f067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "#df=pd.read_csv(\"/content/drive/MyDrive/dt_enzyme_aff.csv\")\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/enzyme_dt_pairs_aff.csv\")\n",
        "df.drop(\"WPath\",axis=1, inplace=True)\n",
        "col_names=df.columns.values.tolist()\n",
        "X = df.iloc[:, :-1].values\n",
        "Y=df.iloc[:, -1].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, stratify=Y,random_state=42)\n",
        "arr=np.column_stack((X_train,y_train))\n",
        "df_new_train=pd.DataFrame(arr)\n",
        "print(X_train)\n",
        "df_new_train.columns=col_names\n",
        "print(df_new_train)\n",
        "positive_set=pd.DataFrame()\n",
        "negative_set=pd.DataFrame()\n",
        "positive_set=df_new_train[df_new_train[\"aff\"]==1]\n",
        "negative_set=df_new_train[df_new_train[\"aff\"]==0]\n",
        "#print(np.any(np.isnan(X_df)))\n",
        "#print(np.any(np.isnan(Y_df)))\n",
        "print(positive_set.shape[0])\n",
        "print(negative_set.shape[0])\n",
        "'MW' in df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I23VcyFibIj2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import math\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.under_sampling import CondensedNearestNeighbour\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import svm\n",
        "\n",
        "drug_set=pd.read_csv(\"/content/drive/MyDrive/enzyme_mordred.csv\")\n",
        "print(drug_set.isnull().sum().sum())\n",
        "drug_set.drop(columns=drug_set.columns[drug_set.nunique()<=2], inplace=True)\n",
        "#drug_reduced_set.drop(columns=drug_reduced_set.columns[drug_reduced_set.nunique()<=2], inplace=True)\n",
        "drug_set.drop(\"WPath\",axis=1, inplace=True)\n",
        "drug_n=drug_set.shape[1]\n",
        "prot_set=pd.read_csv(\"/content/drive/MyDrive/enzyme_propy3_new.csv\")\n",
        "print(prot_set.isnull().sum().sum())\n",
        "prot_set.drop(columns=prot_set.columns[prot_set.nunique()<=2], inplace=True)\n",
        "prot_n=prot_set.shape[1]\n",
        "\n",
        "red_parameter=1\n",
        "drug_feat=int(red_parameter*drug_n)\n",
        "print(drug_feat)\n",
        "prot_feat=int(red_parameter*prot_n)\n",
        "print(prot_feat)\n",
        "neg_set=pd.DataFrame()\n",
        "train_set=pd.DataFrame()\n",
        "new_train_set=pd.DataFrame()\n",
        "subsample_features_drugs=pd.DataFrame()\n",
        "subsample_features_prot=pd.DataFrame()\n",
        "ensem_model_auc=[]\n",
        "ensem_model_prec=[]\n",
        "ensem_model_recall=[]\n",
        "\n",
        "\n",
        "base_prec=[]\n",
        "ensemble_size = 20\n",
        "base_learners = []\n",
        "\n",
        "learner_feature_indices=[]\n",
        "\n",
        "learner_indices=[]\n",
        "b_learner_indices1=[]\n",
        "b_learner_indices2=[]\n",
        "b_learner_indices3=[]\n",
        "b_learner_indices4=[]\n",
        "b_learner_indices5=[]\n",
        "b_learner_indices6=[]\n",
        "b_learner_indices7=[]\n",
        "b_learner_indices8=[]\n",
        "b_learner_indices9=[]\n",
        "b_learner_indices10=[]\n",
        "b_learner_indices11=[]\n",
        "b_learner_indices12=[]\n",
        "b_learner_indices13=[]\n",
        "b_learner_indices14=[]\n",
        "b_learner_indices15=[]\n",
        "b_learner_indices16=[]\n",
        "b_learner_indices17=[]\n",
        "b_learner_indices18=[]\n",
        "b_learner_indices19=[]\n",
        "b_learner_indices20=[]\n",
        "#-----section 1--------\n",
        "i=1\n",
        "for _ in range(ensemble_size):\n",
        "    # We sample rows and columns for each base learner\n",
        " learner_feature_indices=[]\n",
        " n=positive_set.shape[0]\n",
        " #sampling negatives equal to positives (rows ) with replacement\n",
        " #neg_set=negative_set.sample(20*n,axis=0,replace=False)\n",
        " #sampled dataset for each iteration\n",
        " train_set=pd.concat([positive_set, negative_set],axis=0)\n",
        "\n",
        " #TOT=int(0.40*(df_new_train.shape[0]))\n",
        " #df_train=df_new_train.sample(TOT,axis=0,replace=False)\n",
        " #sampling drug features as per red_parameter\n",
        " subsample_features_drugs=drug_set.sample(drug_feat,axis='columns',replace=True)\n",
        " #sampling protein features as per red_parameter\n",
        " subsample_features_prot=prot_set.sample(prot_feat,axis='columns',replace=True)\n",
        " d_list=subsample_features_drugs.columns.values.tolist()\n",
        " p_list=subsample_features_prot.columns.values.tolist()\n",
        " column_list=d_list+p_list\n",
        " column_list.append(\"aff\")\n",
        " #features sampled from tarin_set combining both drug features and protein faetures\n",
        " new_train_set=train_set.filter(column_list)\n",
        " #new_train_set=df_new_train.filter(column_list)\n",
        " X_t = new_train_set.iloc[:, :-1].values\n",
        " Y_t = new_train_set.iloc[:, -1].values\n",
        "\n",
        " #nm=NearMiss(version=3)\n",
        " #cnn=CondensedNearestNeighbour()\n",
        " #tl=TomekLinks()\n",
        " #over = SMOTE()\n",
        " #X_res, Y_res= over.fit_resample(X_t, Y_t)\n",
        " #X_res, Y_res = tl.fit_resample(X_t, Y_t)\n",
        "\n",
        " dtree=DecisionTreeClassifier()\n",
        " #svm_clf=svm.SVC()\n",
        " dtree.fit(X_t,Y_t)\n",
        " base_learners.append(dtree)\n",
        " for colname in column_list:\n",
        "     if colname in train_set.columns and colname !='aff':\n",
        "       feature_index=train_set.columns.get_loc(colname)\n",
        "       learner_feature_indices.append(feature_index)\n",
        " ''' for colname in column_list:\n",
        "     if colname in df_new_train.columns and colname !='aff':\n",
        "       feature_index=df_new_train.columns.get_loc(colname)\n",
        "       learner_feature_indices.append(feature_index)'''\n",
        " indices=np.array(learner_feature_indices)\n",
        "\n",
        " if i==1:\n",
        "    b_learner_indices1.append(indices)\n",
        "\n",
        " elif i==2:\n",
        "    b_learner_indices2.append(indices)\n",
        " elif i==3:\n",
        "    b_learner_indices3.append(indices)\n",
        " elif i==4:\n",
        "    b_learner_indices4.append(indices)\n",
        " elif i==5:\n",
        "    b_learner_indices5.append(indices)\n",
        " elif i==6:\n",
        "    b_learner_indices6.append(indices)\n",
        " elif i==7:\n",
        "    b_learner_indices7.append(indices)\n",
        " elif i==8:\n",
        "    b_learner_indices8.append(indices)\n",
        " elif i==9:\n",
        "    b_learner_indices9.append(indices)\n",
        " elif i==10:\n",
        "    b_learner_indices10.append(indices)\n",
        " elif i==11:\n",
        "    b_learner_indices11.append(indices)\n",
        " elif i==12:\n",
        "    b_learner_indices12.append(indices)\n",
        " elif i==13:\n",
        "    b_learner_indices13.append(indices)\n",
        " elif i==14:\n",
        "    b_learner_indices14.append(indices)\n",
        " elif i==15:\n",
        "    b_learner_indices15.append(indices)\n",
        " elif i==16:\n",
        "    b_learner_indices16.append(indices)\n",
        " elif i==17:\n",
        "    b_learner_indices17.append(indices)\n",
        " elif i==18:\n",
        "    b_learner_indices18.append(indices)\n",
        " elif i==19:\n",
        "    b_learner_indices19.append(indices)\n",
        " elif i==20:\n",
        "    b_learner_indices20.append(indices)\n",
        "\n",
        " else:\n",
        "    print(\"do nothing\")\n",
        " i=i+1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr6jsg23VJR4"
      },
      "outputs": [],
      "source": [
        "# ----SECTION 2 ----\n",
        "# Predict with the base learners and evaluate them\n",
        "predictions=[]\n",
        "base_predictions = []\n",
        "base_prec = []\n",
        "i=1\n",
        "\n",
        "for learner in base_learners:\n",
        "    if i==1:\n",
        "       for x in b_learner_indices1:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==2:\n",
        "       for x in b_learner_indices2:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==3:\n",
        "      for x in b_learner_indices3:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==4:\n",
        "      for x in b_learner_indices4:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==5:\n",
        "       for x in b_learner_indices5:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==6:\n",
        "       for x in b_learner_indices6:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==7:\n",
        "       for x in b_learner_indices7:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==8:\n",
        "      for x in b_learner_indices8:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==9:\n",
        "       for x in b_learner_indices9:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==10:\n",
        "       for x in b_learner_indices10:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==11:\n",
        "       for x in b_learner_indices11:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==12:\n",
        "       for x in b_learner_indices12:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "\n",
        "    elif i==13:\n",
        "       for x in b_learner_indices13:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "\n",
        "    elif i==14:\n",
        "       for x in b_learner_indices14:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==15:\n",
        "       for x in b_learner_indices15:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==16:\n",
        "       for x in b_learner_indices16:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==17:\n",
        "       for x in b_learner_indices17:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==18:\n",
        "       for x in b_learner_indices18:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==19:\n",
        "       for x in b_learner_indices19:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    elif i==20:\n",
        "       for x in b_learner_indices20:\n",
        "         predictions = learner.predict(X_test[:,x])\n",
        "    else:\n",
        "        print(\"do nothing\")\n",
        "    i=i+1\n",
        "\n",
        "    base_predictions.append(predictions)\n",
        "    '''prec = metrics.accuracy_score(y_test, predictions)\n",
        "    base_prec.append(prec)\n",
        "    print(base_prec)'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGygsudI4DSw"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# --- SECTION 3 ---\n",
        "# Combine the base learners' predictions\n",
        "\n",
        "ensemble_predictions = []\n",
        "# voting for each test instance\n",
        "for i in range(len(y_test)):\n",
        "    # Count the votes for each class\n",
        "    counts = [0 for _ in range(20)]\n",
        "    for learner_predictions in base_predictions:\n",
        "        #print(learner_predictions[i])\n",
        "        counts[int(learner_predictions[i])] = counts[int(learner_predictions[i])]+1\n",
        "\n",
        "    # Find the class with most votes\n",
        "    final = np.argmax(counts)\n",
        "    # Add the class to the final predictions\n",
        "    ensemble_predictions.append(final)\n",
        "\n",
        "ensemble_auc = metrics.roc_auc_score(y_test, ensemble_predictions)\n",
        "ensemble_prec = metrics.average_precision_score(y_test, ensemble_predictions)\n",
        "ensemble_precision = metrics.precision_score(y_test, ensemble_predictions)\n",
        "ensemble_recall = metrics.recall_score(y_test, ensemble_predictions)\n",
        "ensemble_fbetascore = metrics.fbeta_score(y_test, ensemble_predictions, beta=0.5)\n",
        "ensemble_mcc = metrics.matthews_corrcoef(y_test, ensemble_predictions)\n",
        "ensemble_class_report = metrics.classification_report(y_test, ensemble_predictions)\n",
        "\n",
        "\n",
        "print('custom voting ensemble: %.2f' % ensemble_auc)\n",
        "print('custom voting ensemble: %.2f' % ensemble_prec)\n",
        "print('custom voting ensemble: %.2f' % ensemble_precision)\n",
        "\n",
        "print('custom voting ensemble: %.2f' % ensemble_recall)\n",
        "print('custom voting ensemble: %.2f' % ensemble_fbetascore)\n",
        "print('custom voting ensemble: %.2f' % ensemble_mcc)\n",
        "\n",
        "print(ensemble_class_report)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''# --- SECTION 4 ---\n",
        "# Print the precision\n",
        "print('Base Learners:')\n",
        "print('-'*30)\n",
        "for index, p in enumerate(sorted(base_prec)):\n",
        "    print(f'Learner {index+1}: %.2f' % p)\n",
        "print('-'*30)\n",
        "print('custom voting ensemble: %.2f' % ensemble_prec)'''\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}